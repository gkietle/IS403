{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pmdarima'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mstatsmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtsa\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marima\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ARIMA\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mstatsmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtsa\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mar_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AutoReg \n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpmdarima\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m auto_arima\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tqdm_notebook\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pmdarima'"
     ]
    }
   ],
   "source": [
    "from statsmodels.graphics.tsaplots import acf, pacf\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.ar_model import AutoReg \n",
    "from pmdarima import auto_arima\n",
    "from tqdm import tqdm_notebook\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.dates as mdates\n",
    "import datetime as dt\n",
    "\n",
    "from itertools import product\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BTC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step #1: Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data\n",
    "df = pd.read_csv('../.dataset/BTC-USD-3.2018-3.2024.csv', parse_dates=['Date'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step #2: Explore the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset Description\n",
    "df = df.set_index('Date')\n",
    "print(f\"Dataset Shape: {df.shape}\")\n",
    "print(f\"Dataset Info: {df.info()}\")\n",
    "print(f\"Dataset Describe: {df.describe()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting data\n",
    "plt.figure(figsize=(15, 7))\n",
    "plt.plot(df.Close, label='BTC/USD Close price')\n",
    "plt.title('BTC/USD Close price')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step #3: Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering\n",
    "def createFeatures(df):\n",
    "    df = pd.DataFrame(df)\n",
    "\n",
    "    \n",
    "    df['Close_Diff'] = df['Adj Close'].diff()\n",
    "        \n",
    "    # Moving averages - different periods\n",
    "    df['MA200'] = df['Close'].rolling(window=200).mean() \n",
    "    df['MA100'] = df['Close'].rolling(window=100).mean() \n",
    "    df['MA50'] = df['Close'].rolling(window=50).mean() \n",
    "    df['MA26'] = df['Close'].rolling(window=26).mean() \n",
    "    df['MA20'] = df['Close'].rolling(window=20).mean() \n",
    "    df['MA12'] = df['Close'].rolling(window=12).mean() \n",
    "    \n",
    "    # SMA Differences - different periods\n",
    "    df['DIFF-MA200-MA50'] = df['MA200'] - df['MA50']\n",
    "    df['DIFF-MA200-MA100'] = df['MA200'] - df['MA100']\n",
    "    df['DIFF-MA200-CLOSE'] = df['MA200'] - df['Close']\n",
    "    df['DIFF-MA100-CLOSE'] = df['MA100'] - df['Close']\n",
    "    df['DIFF-MA50-CLOSE'] = df['MA50'] - df['Close']\n",
    "    \n",
    "    # Moving Averages on high, lows, and std - different periods\n",
    "    df['MA200_low'] = df['Low'].rolling(window=200).min()\n",
    "    df['MA14_low'] = df['Low'].rolling(window=14).min()\n",
    "    df['MA200_high'] = df['High'].rolling(window=200).max()\n",
    "    df['MA14_high'] = df['High'].rolling(window=14).max()\n",
    "    df['MA20dSTD'] = df['Close'].rolling(window=20).std() \n",
    "    \n",
    "    # Exponential Moving Averages (EMAS) - different periods\n",
    "    df['EMA12'] = df['Close'].ewm(span=12, adjust=False).mean()\n",
    "    df['EMA20'] = df['Close'].ewm(span=20, adjust=False).mean()\n",
    "    df['EMA26'] = df['Close'].ewm(span=26, adjust=False).mean()\n",
    "    df['EMA100'] = df['Close'].ewm(span=100, adjust=False).mean()\n",
    "    df['EMA200'] = df['Close'].ewm(span=200, adjust=False).mean()\n",
    "\n",
    "    # Shifts (one day before and two days before)\n",
    "    df['close_shift-1'] = df.shift(-1)['Close']\n",
    "    df['close_shift-2'] = df.shift(-2)['Close']\n",
    "\n",
    "    # Bollinger Bands\n",
    "    df['Bollinger_Upper'] = df['MA20'] + (df['MA20dSTD'] * 2)\n",
    "    df['Bollinger_Lower'] = df['MA20'] - (df['MA20dSTD'] * 2)\n",
    "    df['Bollinger_Middle'] = df['MA20'] \n",
    "    \n",
    "    # Relative Strength Index (RSI)\n",
    "    df['K-ratio'] = 100*((df['Close'] - df['MA14_low']) / (df['MA14_high'] - df['MA14_low']) )\n",
    "    df['RSI'] = df['K-ratio'].rolling(window=3).mean() \n",
    "\n",
    "    # Moving Average Convergence/Divergence (MACD)\n",
    "    df['MACD'] = df['EMA12'] - df['EMA26']\n",
    "    \n",
    "    # Replace nas \n",
    "    nareplace = df.at[df.index.max(), 'Close']    \n",
    "    df.fillna((nareplace), inplace=True)\n",
    "    \n",
    "    # \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of considered Features\n",
    "FEATURES = [\n",
    "            # 'High',\n",
    "            # 'Low',\n",
    "            # 'Open',\n",
    "            'Close',\n",
    "            # 'Volume',\n",
    "#             'Day',\n",
    "#             'Month',\n",
    "#             'Year',\n",
    "            # 'Adj Close',\n",
    "#              'close_shift-1',\n",
    "#              'close_shift-2',\n",
    "            'MACD',\n",
    "            'RSI',\n",
    "            # 'MA200',\n",
    "#             'MA200_high',\n",
    "#             'MA200_low',\n",
    "            'Bollinger_Upper',\n",
    "            'Bollinger_Lower',\n",
    "            # 'MA100',            \n",
    "#             'MA50',\n",
    "            'MA26',\n",
    "#             'MA14_low',\n",
    "#             'MA14_high',\n",
    "            # 'MA12',\n",
    "            'EMA20',\n",
    "            # 'EMA100',\n",
    "#             'EMA200',\n",
    "#               'DIFF-MA200-MA50',\n",
    "#               'DIFF-MA200-MA100',\n",
    "#             'DIFF-MA200-CLOSE',\n",
    "#             'DIFF-MA100-CLOSE',\n",
    "#             'DIFF-MA50-CLOSE',\n",
    "            # 'MA20dSTD',\n",
    "            # 'Close_Diff',\n",
    "            'K-ratio'\n",
    "           ]\n",
    "\n",
    "# Create the dataset with features\n",
    "df_features = createFeatures(df)\n",
    "\n",
    "# Shift the timeframe by 10 month -> Start date is 2010-11-01\n",
    "use_start_date = pd.to_datetime(\"2018-10-01\")\n",
    "df_features = df_features[df_features.index > use_start_date].copy()\n",
    "\n",
    "# Filter the data to the list of FEATURES\n",
    "df_filtered = df_features[FEATURES].copy()\n",
    "\n",
    "# Filter the data to the list of FEATURES\n",
    "print(df_filtered.head().to_string())\n",
    "\n",
    "# Create the lag of FEATURES (1 day before)\n",
    "for feature in FEATURES:\n",
    "   # drop the original feature except for the close price\n",
    "    if feature != 'Close':\n",
    "        df_filtered[feature + '_lag1'] = df_filtered[feature].shift(1)\n",
    "        df_filtered.drop(feature, axis=1, inplace=True)\n",
    "        \n",
    "  \n",
    "    \n",
    "\n",
    "# Filter the data to the list of FEATURES\n",
    "df_filtered = df_filtered.dropna()\n",
    "print(df_filtered.head().to_string())\n",
    "\n",
    "# Create the lineplot\n",
    "plt.figure(figsize=(15, 7))\n",
    "plt.plot(df_filtered)\n",
    "plt.title('BTC/USD Close price')\n",
    "plt.grid()\n",
    "plt.legend(df_filtered.columns)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot line charts\n",
    "df_plot = df_filtered.copy()\n",
    "\n",
    "ncols = 2\n",
    "nrows = int(round(df_plot.shape[1] / ncols, 0))\n",
    "\n",
    "fig, ax = plt.subplots(nrows=nrows, ncols=ncols, sharex=True, figsize=(14, 7))\n",
    "for i, ax in enumerate(fig.axes):\n",
    "        sns.lineplot(data = df_plot.iloc[:, i], ax=ax)\n",
    "        ax.tick_params(axis=\"x\", rotation=30, labelsize=10, length=0)\n",
    "        ax.xaxis.set_major_locator(mdates.AutoDateLocator())\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Coorelation Matrix\n",
    "plt.figure(figsize=(14, 7))\n",
    "sns.heatmap(df_filtered.corr(), annot=True, fmt=\".2f\")\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step #4: Train & Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-Validation-Test Split\n",
    "def split_data(df, test_size=None, valid_size=None):\n",
    "    ntest = int(len(df)*test_size)\n",
    "    nvalid = int(len(df)*valid_size)\n",
    "    ntrain = len(df) - ntest - nvalid\n",
    "    train = df.iloc[:ntrain].copy()\n",
    "    valid = df.iloc[ntrain:ntrain+nvalid].copy()\n",
    "    test = df.iloc[ntrain+nvalid:].copy()\n",
    "    return train, valid, test\n",
    "\n",
    "# Split the data\n",
    "train, valid, test = split_data(df_filtered, test_size=0.25, valid_size=0.1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step #5: Model Specification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ARIMAX**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Check for stationary**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agugmented Dickey-Fuller test\n",
    "def adf_test(dataset, name):\n",
    "    dftest = adfuller(dataset, autolag='AIC', regression='ct')\n",
    "    print(f\"ADF Test on '{name}' -> p-value: {dftest[1]:.3f}\")\n",
    "    # print(\"1. ADF : \",dftest[0])\n",
    "    # Print dataset cols\n",
    "    # print(\"3. Num Of Lags : \", dftest[2])\n",
    "    # print(\"4. Num Of Observations Used For ADF Regression and Critical Values Calculation :\", dftest[3])\n",
    "    # # print(\"5. Critical Values :\")\n",
    "    # for key, val in dftest[4].items():\n",
    "    #    print(\"\\t\",key, \": \", val)\n",
    "    if (dftest[0] < dftest[4][\"5%\"] or dftest[0] < dftest[4][\"1%\"] or dftest[0] < dftest[4][\"10%\"]):\n",
    "        print (\"\\033[92mReject Ho - Time Series is Stationary\\033[0m\")\n",
    "        return True\n",
    "    else:\n",
    "        print (\"\\033[91mFailed to Reject Ho - Time Series is Non-Stationary\\033[0m\")\n",
    "        return False\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Differencing all features for stationarity until all features are stationary\n",
    "is_all_stationary = False\n",
    "diff_order = 0\n",
    "while not is_all_stationary:\n",
    "    print(\"*\"*50 + f\" Differencing of order {diff_order} \" + \"*\"*50)\n",
    "    train_diff = pd.DataFrame(np.diff(train, diff_order, axis=0), columns=train.columns)\n",
    "    if all([adf_test(train_diff[feature], feature) for feature in train_diff.columns]):\n",
    "        is_all_stationary = True\n",
    "        print(f\"Dataset is stationary after differencing of order {diff_order}\")\n",
    "        break\n",
    "    diff_order += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot line charts\n",
    "df_plot = train_diff.copy()\n",
    "\n",
    "ncols = 2\n",
    "nrows = int(round(df_plot.shape[1] / ncols, 0))\n",
    "\n",
    "fig, ax = plt.subplots(nrows=nrows, ncols=ncols, sharex=True, figsize=(14, 7))\n",
    "for i, ax in enumerate(fig.axes):\n",
    "        sns.lineplot(data = df_plot.iloc[:, i], ax=ax)\n",
    "        ax.tick_params(axis=\"x\", rotation=30, labelsize=10, length=0)\n",
    "        ax.xaxis.set_major_locator(mdates.AutoDateLocator())\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot ACF and PACF\n",
    "acf_plot = acf(train_diff['Close'])\n",
    "pacf_plot = pacf(train_diff['Close'])\n",
    "# Plot ACF\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(acf_plot, marker='o', linestyle='--')\n",
    "plt.axhline(y=0, color='gray')\n",
    "plt.axhline(y=-1.96/np.sqrt(len(train_diff)), color='red', linestyle='--')\n",
    "plt.axhline(y=1.96/np.sqrt(len(train_diff)), color='red', linestyle='--')\n",
    "plt.title('ACF')\n",
    "\n",
    "# Plot PACF\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(pacf_plot, marker='o', linestyle='--')\n",
    "plt.axhline(y=0, color='gray')\n",
    "plt.axhline(y=-1.96/np.sqrt(len(train_diff)), color='red', linestyle='--')\n",
    "plt.axhline(y=1.96/np.sqrt(len(train_diff)), color='red', linestyle='--')\n",
    "plt.title('PACF')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Choose the “p” level of AR model and “q” level for MA model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the best ARIMA model\n",
    "def _arima_fit(orders, data, exog=None):\n",
    "    models = dict()\n",
    "    # Print arima fit with AIC and BIC decending\n",
    "    for order in tqdm_notebook(orders):\n",
    "        model = ARIMA(data, order=order, exog=exog)\n",
    "        model_fit = model.fit()\n",
    "        models[order] = model_fit\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate ARIMA models with different p, q values through PCAF and ACF plots\n",
    "list_q = [0, 1, 4, 7] # q values picked from PACF plot\n",
    "list_p = [0, 1, 4, 7] # p values picked from ACF plot\n",
    "order_list = list(product(list_p, [diff_order], list_q))\n",
    "\n",
    "models = _arima_fit(order_list, train['Close'], train.drop(columns=['Close']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Validation and tuning model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate the model with the validation set with AIC and BIC, then pick the best model based on RMSE\n",
    "def _validate_models(models, valid, exog=None):\n",
    "    # Get 10 top models based on AIC\n",
    "    top_models = sorted(models.items(), key=lambda x: x[1].aic)[:10]\n",
    "    print(\"Top 10 models based on AIC\")\n",
    "    for order, model in top_models:\n",
    "        print(f\"Order: {order} -> AIC: {model.aic:.2f}\")\n",
    "    # Validate the models\n",
    "    best_model = None\n",
    "    best_RMSE = float('inf')\n",
    "    best_order = None\n",
    "    for order, model in top_models:\n",
    "        forecast = model.forecast(steps=len(valid), exog=exog)\n",
    "        mse = np.mean((forecast - valid['Close'])**2)\n",
    "        rmse = np.sqrt(mse)\n",
    "        if rmse < best_RMSE:\n",
    "            best_RMSE = rmse\n",
    "            best_model = model\n",
    "            best_order = order\n",
    "    return best_model, best_order, best_RMSE\n",
    "        \n",
    "        \n",
    "\n",
    "# Validate the models\n",
    "best_model, best_order, best_RMSE = _validate_models(models, valid, valid.drop(columns=['Close']))\n",
    "\n",
    "print(f\"\\nBest Order: {best_order} -> Best RMSE: {best_RMSE:.2f}\")\n",
    "print(best_model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Forecasting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forecast on validation set and test set\n",
    "forecast_valid = best_model.forecast(steps=len(valid), exog=valid.drop(columns=['Close']))\n",
    "forecast_valid.index = valid.index\n",
    "# test forecast\n",
    "forecast_test_valid = best_model.forecast(steps=len(test)+len(valid), exog=np.concatenate([valid.drop(columns=['Close']), test.drop(columns=['Close'])]))\n",
    "forecast_test = forecast_test_valid[len(valid):]\n",
    "forecast_test.index = test.index\n",
    "\n",
    "\n",
    "# Create the forecast's exogenous variables\n",
    "num_days_forecast = dt.date(2024, 4, 1) - test.index.max().date()\n",
    "\n",
    "future_exog = test.iloc[-num_days_forecast.days:].mean()\n",
    "df_exog_future = pd.DataFrame([future_exog] * num_days_forecast.days, columns=train.drop(columns=['Close']).columns)\n",
    "df_exog_future.index = pd.date_range(start=test.index.max() + dt.timedelta(days=1), periods=num_days_forecast.days)\n",
    "\n",
    "# Forecast\n",
    "forecast_next_30_days = best_model.forecast(steps=num_days_forecast.days, exog=df_exog_future)\n",
    "forecast_next_30_days.index = df_exog_future.index\n",
    "\n",
    "# Plot the overall\n",
    "plt.figure(figsize=(15, 7))\n",
    "plt.plot(train['Close'], label='Train')\n",
    "plt.plot(valid['Close'], label='Validation')\n",
    "plt.plot(test['Close'], label='Test')\n",
    "plt.plot(forecast_valid, label='Validation Forecast')\n",
    "plt.plot(forecast_test, label='Test Forecast')\n",
    "plt.plot(forecast_next_30_days, label='Next 30 days Forecast')\n",
    "plt.title('BTC/USD Close price')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the forecast\n",
    "plt.figure(figsize=(15, 7))\n",
    "plt.plot(valid['Close'], label='Validation')\n",
    "plt.plot(test['Close'], label='Test')\n",
    "plt.plot(valid.index, forecast_valid, label='Forecast Validation')\n",
    "plt.plot(test.index, forecast_test, label='Forecast Test')\n",
    "plt.plot(forecast_next_30_days, label='Forecast Next 30 Days')\n",
    "plt.title('BTC/USD Close price')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step #6: Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the Model's RMSE, MAPE, and SMAPE\n",
    "def calculate_metrics(y_true, y_pred):\n",
    "    rmse = np.sqrt(np.mean((y_true - y_pred)**2))\n",
    "    mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "    smape = np.mean((np.abs(y_pred - y_true) * 200 / (np.abs(y_pred) + np.abs(y_true))))\n",
    "    return rmse, mape, smape\n",
    "\n",
    "# Calculate the metrics\n",
    "rmse, mape, smape = calculate_metrics(test['Close'], forecast_test)\n",
    "print(f\"RMSE: {rmse:.2f}\")\n",
    "print(f\"MAPE: {mape:.2f}\")\n",
    "print(f\"SMAPE: {smape:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ETH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step #1: Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data\n",
    "df = pd.read_csv('../.dataset/BTC-USD-3.2018-3.2024.csv', parse_dates=['Date'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step #2: Explore the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset Description\n",
    "df = df.set_index('Date')\n",
    "print(f\"Dataset Shape: {df.shape}\")\n",
    "print(f\"Dataset Info: {df.info()}\")\n",
    "print(f\"Dataset Describe: {df.describe()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting data\n",
    "plt.figure(figsize=(15, 7))\n",
    "plt.plot(df.Close, label='BTC/USD Close price')\n",
    "plt.title('BTC/USD Close price')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step #3: Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering\n",
    "def createFeatures(df):\n",
    "    df = pd.DataFrame(df)\n",
    "\n",
    "    \n",
    "    df['Close_Diff'] = df['Adj Close'].diff()\n",
    "        \n",
    "    # Moving averages - different periods\n",
    "    df['MA200'] = df['Close'].rolling(window=200).mean() \n",
    "    df['MA100'] = df['Close'].rolling(window=100).mean() \n",
    "    df['MA50'] = df['Close'].rolling(window=50).mean() \n",
    "    df['MA26'] = df['Close'].rolling(window=26).mean() \n",
    "    df['MA20'] = df['Close'].rolling(window=20).mean() \n",
    "    df['MA12'] = df['Close'].rolling(window=12).mean() \n",
    "    \n",
    "    # SMA Differences - different periods\n",
    "    df['DIFF-MA200-MA50'] = df['MA200'] - df['MA50']\n",
    "    df['DIFF-MA200-MA100'] = df['MA200'] - df['MA100']\n",
    "    df['DIFF-MA200-CLOSE'] = df['MA200'] - df['Close']\n",
    "    df['DIFF-MA100-CLOSE'] = df['MA100'] - df['Close']\n",
    "    df['DIFF-MA50-CLOSE'] = df['MA50'] - df['Close']\n",
    "    \n",
    "    # Moving Averages on high, lows, and std - different periods\n",
    "    df['MA200_low'] = df['Low'].rolling(window=200).min()\n",
    "    df['MA14_low'] = df['Low'].rolling(window=14).min()\n",
    "    df['MA200_high'] = df['High'].rolling(window=200).max()\n",
    "    df['MA14_high'] = df['High'].rolling(window=14).max()\n",
    "    df['MA20dSTD'] = df['Close'].rolling(window=20).std() \n",
    "    \n",
    "    # Exponential Moving Averages (EMAS) - different periods\n",
    "    df['EMA12'] = df['Close'].ewm(span=12, adjust=False).mean()\n",
    "    df['EMA20'] = df['Close'].ewm(span=20, adjust=False).mean()\n",
    "    df['EMA26'] = df['Close'].ewm(span=26, adjust=False).mean()\n",
    "    df['EMA100'] = df['Close'].ewm(span=100, adjust=False).mean()\n",
    "    df['EMA200'] = df['Close'].ewm(span=200, adjust=False).mean()\n",
    "\n",
    "    # Shifts (one day before and two days before)\n",
    "    df['close_shift-1'] = df.shift(-1)['Close']\n",
    "    df['close_shift-2'] = df.shift(-2)['Close']\n",
    "\n",
    "    # Bollinger Bands\n",
    "    df['Bollinger_Upper'] = df['MA20'] + (df['MA20dSTD'] * 2)\n",
    "    df['Bollinger_Lower'] = df['MA20'] - (df['MA20dSTD'] * 2)\n",
    "    df['Bollinger_Middle'] = df['MA20'] \n",
    "    \n",
    "    # Relative Strength Index (RSI)\n",
    "    df['K-ratio'] = 100*((df['Close'] - df['MA14_low']) / (df['MA14_high'] - df['MA14_low']) )\n",
    "    df['RSI'] = df['K-ratio'].rolling(window=3).mean() \n",
    "\n",
    "    # Moving Average Convergence/Divergence (MACD)\n",
    "    df['MACD'] = df['EMA12'] - df['EMA26']\n",
    "    \n",
    "    # Replace nas \n",
    "    nareplace = df.at[df.index.max(), 'Close']    \n",
    "    df.fillna((nareplace), inplace=True)\n",
    "    \n",
    "    # \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of considered Features\n",
    "FEATURES = [\n",
    "            # 'High',\n",
    "            # 'Low',\n",
    "            # 'Open',\n",
    "            'Close',\n",
    "            # 'Volume',\n",
    "#             'Day',\n",
    "#             'Month',\n",
    "#             'Year',\n",
    "            # 'Adj Close',\n",
    "#              'close_shift-1',\n",
    "#              'close_shift-2',\n",
    "            'MACD',\n",
    "            'RSI',\n",
    "            # 'MA200',\n",
    "#             'MA200_high',\n",
    "#             'MA200_low',\n",
    "            'Bollinger_Upper',\n",
    "            'Bollinger_Lower',\n",
    "            # 'MA100',            \n",
    "#             'MA50',\n",
    "            'MA26',\n",
    "#             'MA14_low',\n",
    "#             'MA14_high',\n",
    "            # 'MA12',\n",
    "            'EMA20',\n",
    "            # 'EMA100',\n",
    "#             'EMA200',\n",
    "#               'DIFF-MA200-MA50',\n",
    "#               'DIFF-MA200-MA100',\n",
    "#             'DIFF-MA200-CLOSE',\n",
    "#             'DIFF-MA100-CLOSE',\n",
    "#             'DIFF-MA50-CLOSE',\n",
    "            # 'MA20dSTD',\n",
    "            # 'Close_Diff',\n",
    "            'K-ratio'\n",
    "           ]\n",
    "\n",
    "# Create the dataset with features\n",
    "df_features = createFeatures(df)\n",
    "\n",
    "# Shift the timeframe by 10 month -> Start date is 2010-11-01\n",
    "use_start_date = pd.to_datetime(\"2018-10-01\")\n",
    "df_features = df_features[df_features.index > use_start_date].copy()\n",
    "\n",
    "# Filter the data to the list of FEATURES\n",
    "df_filtered = df_features[FEATURES].copy()\n",
    "\n",
    "# Filter the data to the list of FEATURES\n",
    "print(df_filtered.head().to_string())\n",
    "\n",
    "# Create the lag of FEATURES (1 day before)\n",
    "for feature in FEATURES:\n",
    "   # drop the original feature except for the close price\n",
    "    if feature != 'Close':\n",
    "        df_filtered[feature + '_lag1'] = df_filtered[feature].shift(1)\n",
    "        df_filtered.drop(feature, axis=1, inplace=True)\n",
    "        \n",
    "  \n",
    "    \n",
    "\n",
    "# Filter the data to the list of FEATURES\n",
    "df_filtered = df_filtered.dropna()\n",
    "print(df_filtered.head().to_string())\n",
    "\n",
    "# Create the lineplot\n",
    "plt.figure(figsize=(15, 7))\n",
    "plt.plot(df_filtered)\n",
    "plt.title('BTC/USD Close price')\n",
    "plt.grid()\n",
    "plt.legend(df_filtered.columns)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot line charts\n",
    "df_plot = df_filtered.copy()\n",
    "\n",
    "ncols = 2\n",
    "nrows = int(round(df_plot.shape[1] / ncols, 0))\n",
    "\n",
    "fig, ax = plt.subplots(nrows=nrows, ncols=ncols, sharex=True, figsize=(14, 7))\n",
    "for i, ax in enumerate(fig.axes):\n",
    "        sns.lineplot(data = df_plot.iloc[:, i], ax=ax)\n",
    "        ax.tick_params(axis=\"x\", rotation=30, labelsize=10, length=0)\n",
    "        ax.xaxis.set_major_locator(mdates.AutoDateLocator())\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Coorelation Matrix\n",
    "plt.figure(figsize=(14, 7))\n",
    "sns.heatmap(df_filtered.corr(), annot=True, fmt=\".2f\")\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step #4: Train & Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-Validation-Test Split\n",
    "def split_data(df, test_size=None, valid_size=None):\n",
    "    ntest = int(len(df)*test_size)\n",
    "    nvalid = int(len(df)*valid_size)\n",
    "    ntrain = len(df) - ntest - nvalid\n",
    "    train = df.iloc[:ntrain].copy()\n",
    "    valid = df.iloc[ntrain:ntrain+nvalid].copy()\n",
    "    test = df.iloc[ntrain+nvalid:].copy()\n",
    "    return train, valid, test\n",
    "\n",
    "# Split the data\n",
    "train, valid, test = split_data(df_filtered, test_size=0.25, valid_size=0.1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step #5: Model Specification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ARIMAX**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Check for stationary**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agugmented Dickey-Fuller test\n",
    "def adf_test(dataset, name):\n",
    "    dftest = adfuller(dataset, autolag='AIC', regression='ct')\n",
    "    print(f\"ADF Test on '{name}' -> p-value: {dftest[1]:.3f}\")\n",
    "    # print(\"1. ADF : \",dftest[0])\n",
    "    # Print dataset cols\n",
    "    # print(\"3. Num Of Lags : \", dftest[2])\n",
    "    # print(\"4. Num Of Observations Used For ADF Regression and Critical Values Calculation :\", dftest[3])\n",
    "    # # print(\"5. Critical Values :\")\n",
    "    # for key, val in dftest[4].items():\n",
    "    #    print(\"\\t\",key, \": \", val)\n",
    "    if (dftest[0] < dftest[4][\"5%\"] or dftest[0] < dftest[4][\"1%\"] or dftest[0] < dftest[4][\"10%\"]):\n",
    "        print (\"\\033[92mReject Ho - Time Series is Stationary\\033[0m\")\n",
    "        return True\n",
    "    else:\n",
    "        print (\"\\033[91mFailed to Reject Ho - Time Series is Non-Stationary\\033[0m\")\n",
    "        return False\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Differencing all features for stationarity until all features are stationary\n",
    "is_all_stationary = False\n",
    "diff_order = 0\n",
    "while not is_all_stationary:\n",
    "    print(\"*\"*50 + f\" Differencing of order {diff_order} \" + \"*\"*50)\n",
    "    train_diff = pd.DataFrame(np.diff(train, diff_order, axis=0), columns=train.columns)\n",
    "    if all([adf_test(train_diff[feature], feature) for feature in train_diff.columns]):\n",
    "        is_all_stationary = True\n",
    "        print(f\"Dataset is stationary after differencing of order {diff_order}\")\n",
    "        break\n",
    "    diff_order += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot line charts\n",
    "df_plot = train_diff.copy()\n",
    "\n",
    "ncols = 2\n",
    "nrows = int(round(df_plot.shape[1] / ncols, 0))\n",
    "\n",
    "fig, ax = plt.subplots(nrows=nrows, ncols=ncols, sharex=True, figsize=(14, 7))\n",
    "for i, ax in enumerate(fig.axes):\n",
    "        sns.lineplot(data = df_plot.iloc[:, i], ax=ax)\n",
    "        ax.tick_params(axis=\"x\", rotation=30, labelsize=10, length=0)\n",
    "        ax.xaxis.set_major_locator(mdates.AutoDateLocator())\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot ACF and PACF\n",
    "acf_plot = acf(train_diff['Close'])\n",
    "pacf_plot = pacf(train_diff['Close'])\n",
    "# Plot ACF\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(acf_plot, marker='o', linestyle='--')\n",
    "plt.axhline(y=0, color='gray')\n",
    "plt.axhline(y=-1.96/np.sqrt(len(train_diff)), color='red', linestyle='--')\n",
    "plt.axhline(y=1.96/np.sqrt(len(train_diff)), color='red', linestyle='--')\n",
    "plt.title('ACF')\n",
    "\n",
    "# Plot PACF\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(pacf_plot, marker='o', linestyle='--')\n",
    "plt.axhline(y=0, color='gray')\n",
    "plt.axhline(y=-1.96/np.sqrt(len(train_diff)), color='red', linestyle='--')\n",
    "plt.axhline(y=1.96/np.sqrt(len(train_diff)), color='red', linestyle='--')\n",
    "plt.title('PACF')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Choose the “p” level of AR model and “q” level for MA model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the best ARIMA model\n",
    "def _arima_fit(orders, data, exog=None):\n",
    "    models = dict()\n",
    "    # Print arima fit with AIC and BIC decending\n",
    "    for order in tqdm_notebook(orders):\n",
    "        model = ARIMA(data, order=order, exog=exog)\n",
    "        model_fit = model.fit()\n",
    "        models[order] = model_fit\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate ARIMA models with different p, q values through PCAF and ACF plots\n",
    "list_q = [0, 1, 4, 7] # q values picked from PACF plot\n",
    "list_p = [0, 1, 4, 7] # p values picked from ACF plot\n",
    "order_list = list(product(list_p, [diff_order], list_q))\n",
    "\n",
    "models = _arima_fit(order_list, train['Close'], train.drop(columns=['Close']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Validation and tuning model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate the model with the validation set with AIC and BIC, then pick the best model based on RMSE\n",
    "def _validate_models(models, valid, exog=None):\n",
    "    # Get 10 top models based on AIC\n",
    "    top_models = sorted(models.items(), key=lambda x: x[1].aic)[:10]\n",
    "    print(\"Top 10 models based on AIC\")\n",
    "    for order, model in top_models:\n",
    "        print(f\"Order: {order} -> AIC: {model.aic:.2f}\")\n",
    "    # Validate the models\n",
    "    best_model = None\n",
    "    best_RMSE = float('inf')\n",
    "    best_order = None\n",
    "    for order, model in top_models:\n",
    "        forecast = model.forecast(steps=len(valid), exog=exog)\n",
    "        mse = np.mean((forecast - valid['Close'])**2)\n",
    "        rmse = np.sqrt(mse)\n",
    "        if rmse < best_RMSE:\n",
    "            best_RMSE = rmse\n",
    "            best_model = model\n",
    "            best_order = order\n",
    "    return best_model, best_order, best_RMSE\n",
    "        \n",
    "        \n",
    "\n",
    "# Validate the models\n",
    "best_model, best_order, best_RMSE = _validate_models(models, valid, valid.drop(columns=['Close']))\n",
    "\n",
    "print(f\"\\nBest Order: {best_order} -> Best RMSE: {best_RMSE:.2f}\")\n",
    "print(best_model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Forecasting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forecast on validation set and test set\n",
    "forecast_valid = best_model.forecast(steps=len(valid), exog=valid.drop(columns=['Close']))\n",
    "forecast_valid.index = valid.index\n",
    "# test forecast\n",
    "forecast_test_valid = best_model.forecast(steps=len(test)+len(valid), exog=np.concatenate([valid.drop(columns=['Close']), test.drop(columns=['Close'])]))\n",
    "forecast_test = forecast_test_valid[len(valid):]\n",
    "forecast_test.index = test.index\n",
    "\n",
    "\n",
    "# Create the forecast's exogenous variables\n",
    "num_days_forecast = dt.date(2024, 4, 1) - test.index.max().date()\n",
    "\n",
    "future_exog = test.iloc[-num_days_forecast.days:].mean()\n",
    "df_exog_future = pd.DataFrame([future_exog] * num_days_forecast.days, columns=train.drop(columns=['Close']).columns)\n",
    "df_exog_future.index = pd.date_range(start=test.index.max() + dt.timedelta(days=1), periods=num_days_forecast.days)\n",
    "\n",
    "# Forecast\n",
    "forecast_next_30_days = best_model.forecast(steps=num_days_forecast.days, exog=df_exog_future)\n",
    "forecast_next_30_days.index = df_exog_future.index\n",
    "\n",
    "# Plot the overall\n",
    "plt.figure(figsize=(15, 7))\n",
    "plt.plot(train['Close'], label='Train')\n",
    "plt.plot(valid['Close'], label='Validation')\n",
    "plt.plot(test['Close'], label='Test')\n",
    "plt.plot(forecast_valid, label='Validation Forecast')\n",
    "plt.plot(forecast_test, label='Test Forecast')\n",
    "plt.plot(forecast_next_30_days, label='Next 30 days Forecast')\n",
    "plt.title('BTC/USD Close price')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the forecast\n",
    "plt.figure(figsize=(15, 7))\n",
    "plt.plot(valid['Close'], label='Validation')\n",
    "plt.plot(test['Close'], label='Test')\n",
    "plt.plot(valid.index, forecast_valid, label='Forecast Validation')\n",
    "plt.plot(test.index, forecast_test, label='Forecast Test')\n",
    "plt.plot(forecast_next_30_days, label='Forecast Next 30 Days')\n",
    "plt.title('BTC/USD Close price')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step #6: Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the Model's RMSE, MAPE, and SMAPE\n",
    "def calculate_metrics(y_true, y_pred):\n",
    "    rmse = np.sqrt(np.mean((y_true - y_pred)**2))\n",
    "    mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "    smape = np.mean((np.abs(y_pred - y_true) * 200 / (np.abs(y_pred) + np.abs(y_true))))\n",
    "    return rmse, mape, smape\n",
    "\n",
    "# Calculate the metrics\n",
    "rmse, mape, smape = calculate_metrics(test['Close'], forecast_test)\n",
    "print(f\"RMSE: {rmse:.2f}\")\n",
    "print(f\"MAPE: {mape:.2f}\")\n",
    "print(f\"SMAPE: {smape:.2f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
